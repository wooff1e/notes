{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and serialize\n",
    "Keras model consists of:\n",
    "\n",
    "- architecture\n",
    "- weights (the \"state of the model\")\n",
    "- optimizer\n",
    "- losses and metrics\n",
    "\n",
    "You can save:\n",
    "- everything at once as a TensorFlow SavedModel (or older Keras H5 format)\n",
    "- only architecture (doesn't apply to subclassed models)\n",
    "- only weights (generally used when training the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "inputs = tf.keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old format\n",
    "model.save(\"data/model\", save_format='h5')\n",
    "model.save(\"data/model.h5\")\n",
    "model.save(\"data/model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SavedModel format enables Keras to restore both built-in layers as well as custom objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = np.random.random((128, 32))\n",
    "test_target = np.random.random((128, 1))\n",
    "model.fit(test_input, test_target)\n",
    "\n",
    "# save the entire model as a single file\n",
    "model.save(\"data/model\")\n",
    "del model\n",
    "\n",
    "# Recreate the exact same model purely from the file:\n",
    "model = tf.keras.models.load_model(\"data/model\")\n",
    "\n",
    "# The reconstructed model is already compiled and has retained the optimizer state,\n",
    "# so training can resume:\n",
    "model.fit(test_input, test_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When saving the model and its layers, the SavedModel format stores the class name, call() function, losses, and weights (and the config, if implemented). The call function defines the computation graph of the model/layer.\n",
    "\n",
    "In the absence of the model/layer config, the call function is used to create a model that exists like the original model which can be trained, evaluated, and used for inference.\n",
    "\n",
    "Nevertheless, it is always a good practice to define the get_config and from_config methods when writing a custom model or layer class. This allows you to easily update the computation later if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, hidden_units):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.dense_layers = [tf.keras.layers.Dense(u) for u in hidden_units]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.dense_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"hidden_units\": self.hidden_units}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "model = CustomModel([16, 16, 10])\n",
    "# Build the model by calling it\n",
    "input_arr = tf.random.uniform((1, 5))\n",
    "outputs = model(input_arr)\n",
    "model.save(\"my_model\")\n",
    "\n",
    "# Option 1: Load with the custom_object argument.\n",
    "loaded_1 = tf.keras.models.load_model(\n",
    "    \"my_model\", custom_objects={\"CustomModel\": CustomModel}\n",
    ")\n",
    "\n",
    "# Option 2: Load without the CustomModel class.\n",
    "\n",
    "# Delete the custom-defined model class to ensure that the loader does not have\n",
    "# access to it.\n",
    "del CustomModel\n",
    "\n",
    "loaded_2 = tf.keras.models.load_model(\"my_model\")\n",
    "np.testing.assert_allclose(loaded_1(input_arr), outputs)\n",
    "np.testing.assert_allclose(loaded_2(input_arr), outputs)\n",
    "\n",
    "print(\"Original model:\", model)\n",
    "print(\"Model Loaded with custom objects:\", loaded_1)\n",
    "print(\"Model loaded without the custom object class:\", loaded_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he first loaded model is loaded using the config and CustomModel class. The second model is loaded by dynamically creating the model class that acts like the original model.\n",
    "\n",
    "#### Configuring the SavedModel\n",
    "New in TensoFlow 2.4 The argument save_traces has been added to model.save, which allows you to toggle SavedModel function tracing. Functions are saved to allow the Keras to re-load custom objects without the original class definitons, so when save_traces=False, all custom objects must have defined get_config/from_config methods. When loading, the custom objects must be passed to the custom_objects argument. save_traces=False reduces the disk space used by the SavedModel and saving time.\n",
    "\n",
    "### Saving the architecture\n",
    "Sequential model and Functional API model are explicit graphs of layers: their configuration is always available in a structured form.\n",
    "1. **get_config() / from_config()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers\n",
    "layer = tf.keras.layers.Dense(3, activation=\"relu\")\n",
    "layer_config = layer.get_config()\n",
    "new_layer = tf.keras.layers.Dense.from_config(layer_config)\n",
    "\n",
    "# Sequential\n",
    "model = tf.keras.Sequential([tf.keras.Input((32,)), layers.Dense(1)])\n",
    "config = model.get_config()\n",
    "new_model = tf.keras.Sequential.from_config(config)\n",
    "\n",
    "# Functional\n",
    "inputs = tf.keras.Input((32,))\n",
    "outputs = layers.Dense(1)(inputs)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "config = model.get_config()\n",
    "new_model = tf.keras.Model.from_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **model_to_json() / model_from_json()**\n",
    "\n",
    "Turns the model into a JSON string, which can then be loaded without the original model class. It is also specific to models, it isn't meant for layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.Input((32,)), tf.keras.layers.Dense(1)])\n",
    "json_config = model.to_json()\n",
    "new_model = tf.keras.models.model_from_json(json_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom objects\n",
    "### Custom Models and layers\n",
    "In order to save/load a model with custom-defined layers, or a subclassed model, you should overwrite the get_config and optionally from_config methods. Additionally, you should register the custom object so that Keras is aware of it.\n",
    "\n",
    "Keras keeps a master list of all built-in layer, model, optimizer, and metric classes, which is used to find the correct class to call from_config. If the class can't be found, then an error is raised (Value Error: Unknown layer). There are a few ways to register custom classes to this list:\n",
    "\n",
    "1. Setting custom_objects argument in the loading function.\n",
    "2. tf.keras.utils.custom_object_scope or tf.keras.utils.CustomObjectScope\n",
    "3. tf.keras.utils.register_keras_serializable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, a):\n",
    "        self.var = tf.Variable(a, name=\"var_a\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        if training:\n",
    "            return inputs * self.var\n",
    "        else:\n",
    "            return inputs\n",
    "\n",
    "    # should return a JSON-serializable dictionary\n",
    "    def get_config(self):\n",
    "        return {\"a\": self.var.numpy()}\n",
    "\n",
    "    # should return a new layer or model object\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config) # this is actually the default behavior\n",
    "\n",
    "\n",
    "layer = CustomLayer(5)\n",
    "layer.var.assign(2)\n",
    "\n",
    "serialized_layer = tf.keras.layers.serialize(layer)\n",
    "new_layer = tf.keras.layers.deserialize(\n",
    "    serialized_layer, custom_objects={\"CustomLayer\": CustomLayer}\n",
    ")\n",
    "# this generates a serialized form of the custom layer:\n",
    "# {'class_name': 'CustomLayer', 'config': {'a': 2} }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions\n",
    "The function name is sufficient for loading as long as it is registered as a custom object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32, **kwargs):\n",
    "        super(CustomLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CustomLayer, self).get_config()\n",
    "        config.update({\"units\": self.units})\n",
    "        return config\n",
    "\n",
    "\n",
    "def custom_activation(x):\n",
    "    return tf.nn.tanh(x) ** 2\n",
    "\n",
    "\n",
    "# Make a model with the CustomLayer and custom_activation\n",
    "inputs = tf.keras.Input((32,))\n",
    "x = CustomLayer(32)(inputs)\n",
    "outputs = tf.keras.layers.Activation(custom_activation)(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Retrieve the config\n",
    "config = model.get_config()\n",
    "\n",
    "# At loading time, register the custom objects with a `custom_object_scope`:\n",
    "custom_objects = {\"CustomLayer\": CustomLayer, \"custom_activation\": custom_activation}\n",
    "with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "    new_model = tf.keras.Model.from_config(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the TensorFlow graph only\n",
    "It's possible to load the TensorFlow graph generated by the Keras. If you do so, you won't need to provide any custom_objects. \n",
    "\n",
    "    model.save(\"my_model\")\n",
    "    tensorflow_graph = tf.saved_model.load(\"my_model\")\n",
    "    x = np.random.uniform(size=(4, 32)).astype(np.float32)\n",
    "    predicted = tensorflow_graph(x).numpy()\n",
    "\n",
    "Note that the loaded object will not be a Keras model, eg., you won't have access to predict() or fit(). Don't use this method unless you're in a tight spot.\n",
    "\n",
    "### In-memory model cloning\n",
    "\n",
    "This is equivalent to getting the config then recreating the model from its config (so it does not preserve compilation information or layer weights values).\n",
    "\n",
    "    with keras.utils.custom_object_scope(custom_objects):\n",
    "        new_model = keras.models.clone_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving only weights\n",
    "\n",
    "- You only need the model for inference: in this case you won't need to restart training, so you don't need the compilation information or optimizer state.\n",
    "- You are doing transfer learning: in this case you will be training a new model reusing the state of a prior model, so you don't need the compilation information of the prior model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer():\n",
    "    layer = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")\n",
    "    layer.build((None, 784))\n",
    "    return layer\n",
    "\n",
    "layer_1 = create_layer()\n",
    "layer_2 = create_layer()\n",
    "\n",
    "# Copy weights from layer 1 to layer 2\n",
    "layer_2.set_weights(layer_1.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that stateless layers do not change the order or number of weights, so models can have compatible architectures even if there are extra/missing stateless layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(784,), name=\"digits\")\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = tf.keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model = tf.keras.Model(\n",
    "    inputs=inputs, outputs=outputs, name=\"3_layer_mlp\"\n",
    ")\n",
    "\n",
    "inputs = tf.keras.Input(shape=(784,), name=\"digits\")\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)    # does not contain any weights\n",
    "outputs = tf.keras.layers.Dense(10, name=\"predictions\")(x)\n",
    "functional_model_with_dropout = tf.keras.Model(\n",
    "    inputs=inputs, outputs=outputs, name=\"3_layer_mlp\"\n",
    ")\n",
    "\n",
    "functional_model_with_dropout.set_weights(functional_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving weights to disk\n",
    "#### Chekpoint format\n",
    "This format saves and restores the weights using object attribute names. Eg. `tf.keras.layers.Dense` layer contains two weights: `dense.kernel` and `dense.bias` --> the resulting checkpoint contains the keys \"kernel\" and \"bias\" and their corresponding weight values.\n",
    "\n",
    "    class CustomLayer(keras.layers.Layer):\n",
    "        def __init__(self, a):\n",
    "            self.var = tf.Variable(a, name=\"var_a\")\n",
    "\n",
    "The variable CustomLayer.var is saved with \"var\" as part of key, not \"var_a\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Checkpoint format\n",
    "sequential_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(784,), name=\"digits\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "        tf.keras.layers.Dense(10, name=\"predictions\"),\n",
    "    ]\n",
    ")\n",
    "sequential_model.save_weights(\"ckpt\")\n",
    "load_status = sequential_model.load_weights(\"ckpt\")\n",
    "\n",
    "# validate that all variable values have been restored from the checkpoint\n",
    "load_status.assert_consumed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, as long as two models have the same architecture, they are able to share the same checkpoint. It is generally recommended to stick to the same API for building models. If you switch between Sequential and Functional, or Functional and subclassed, etc., then always rebuild the pre-trained model and load the pre-trained weights to that model.\n",
    "\n",
    "The next question is, how can weights be saved and loaded to different models if the model architectures are quite different? The solution is to use tf.train.Checkpoint to save and restore the exact layers/variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subclassed model that essentially uses functional_model's first\n",
    "# and last layers.\n",
    "# First, save the weights of functional_model's first and last dense layers.\n",
    "first_dense = functional_model.layers[1]\n",
    "last_dense = functional_model.layers[-1]\n",
    "ckpt_path = tf.train.Checkpoint(\n",
    "    dense=first_dense, kernel=last_dense.kernel, bias=last_dense.bias\n",
    ").save(\"ckpt\")\n",
    "\n",
    "# Define the subclassed model.\n",
    "class ContrivedModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ContrivedModel, self).__init__()\n",
    "        self.first_dense = tf.keras.layers.Dense(64)\n",
    "        self.kernel = self.add_variable(\"kernel\", shape=(64, 10))\n",
    "        self.bias = self.add_variable(\"bias\", shape=(10,))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.first_dense(inputs)\n",
    "        return tf.matmul(x, self.kernel) + self.bias\n",
    "\n",
    "\n",
    "model = ContrivedModel()\n",
    "# Call model on inputs to create the variables of the dense layer.\n",
    "_ = model(tf.ones((1, 784)))\n",
    "\n",
    "# Create a Checkpoint with the same structure as before, and load the weights.\n",
    "tf.train.Checkpoint(\n",
    "    dense=model.first_dense, kernel=model.kernel, bias=model.bias\n",
    ").restore(ckpt_path).assert_consumed()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5 format\n",
    "The HDF5 format contains weights grouped by layer names. The weights are lists ordered by concatenating the list of trainable weights to the list of non-trainable weights (same as layer.weights). Thus, a model can use a hdf5 checkpoint if it has the same layers and trainable statuses as saved in the checkpoint.\n",
    "\n",
    "When loading pretrained weights from HDF5, it is recommended to load the weights into the original checkpointed model, and then extract the desired weights/layers into a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(784,), name=\"digits\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"dense_1\"),\n",
    "        layers.Dense(64, activation=\"relu\", name=\"dense_2\"),\n",
    "        layers.Dense(10, name=\"predictions\"),\n",
    "    ]\n",
    ")\n",
    "sequential_model.save_weights(\"weights.h5\")\n",
    "#or\n",
    "sequential_model.save_weights(\"weights\", save_format=\"h5\")\n",
    "\n",
    "sequential_model.load_weights(\"weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
